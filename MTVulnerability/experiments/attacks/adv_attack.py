import os, sys, datetime, time
from comet_ml import Experiment

import argparse

from learning.dataloader import get_loader, get_info
from experiments.attacks import load_model, init_comet, abbrev_to_task, TASKONOMY_DATASET
from models.mtask_losses import get_losses_and_tasks
from utils.art.attacks.pytorch_mtask import mtask_forone_advacc


parser = argparse.ArgumentParser(description='Run Adversarial attacks experiments')
parser.add_argument('--arch', type=str, default="resnet18")
parser.add_argument('--dataset', type=str, default="taskonomy")
parser.add_argument('--model_root', type=str, default=None)
parser.add_argument('--data_dir', type=str, default=TASKONOMY_DATASET)
parser.add_argument('--train_task_set', default="ds")
parser.add_argument('--aux_task_set', default="")
parser.add_argument('--test_task_set', default="")
parser.add_argument('--target_task_set', default="")
parser.add_argument('--step_size', type=int, default=2)
parser.add_argument('--epoch', type=str, default="150")
parser.add_argument('--test_batch_size',type=int, default=32)
parser.add_argument('--classes',type=int, default=18)
parser.add_argument('--epsilon',type=int, default=16)
parser.add_argument('--workers',type=int, default=8)
parser.add_argument('--pixel_scale',type=int, default=255)
parser.add_argument('--steps', type=int, default=25)
parser.add_argument('--debug', action='store_true')
parser.add_argument('--timestamp', type=str, default=None)
parser.add_argument('--strategy', type=str, default="None")
parser.add_argument('--name', type=str, default="robust-mtl-RQ2_2")
parser.add_argument('--norm', type=str, default="Linf")
parser.add_argument('--metrics', type=str, default="vuln")
parser.add_argument('--store_examples', type=int, default=0)
args = parser.parse_args()

default_model_root = os.path.join(".","output",args.dataset,
      "train_{arch}_{dataset}_2021-01-20_19-18-12_9b01b470_trainset_{train}{aux}_testset_{test}_lambda_0.01_seed_42_lrs_120_140")
args.model_root = default_model_root if args.model_root is None else args.model_root
args.timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H-%M-%S')

def run(args):

    args_dict = args.__dict__
    for a in args_dict.keys():
        val = args_dict.get(a)
        if isinstance(val,str):
            setattr(args,a,val.replace("\r", ""))

    experiment = init_comet(args,project_name=args.name) if args.name != "#" else None

    args.train_task_set, args.target_task_set, args.test_task_set, args.aux_task_set = \
        abbrev_to_task(args.train_task_set), abbrev_to_task(args.target_task_set), abbrev_to_task(args.test_task_set), \
        abbrev_to_task(args.aux_task_set)


    model = load_model(args)
    args.task_set = args.test_task_set
    target_task = args.target_task_set

    val_loader = get_loader(args, "val", out_name=True)
    criteria, tasks = get_losses_and_tasks(args)
    info = get_info(args.dataset)


    dict_losses2 = mtask_forone_advacc(val_loader, model, criteria, target_task, args, info, test_vis=True,
                                       norm=args.norm,comet=experiment)



if __name__ == '__main__':

    if len(args.train_task_set) == 0:
        exit()

    if len(args.test_task_set) == 0:
        args.test_task_set = args.train_task_set

    if len(args.target_task_set) == 0:
        args.target_task_set = args.train_task_set

    if args.test_task_set.find("+") >-1:
        args.train_task_set = args.train_task_set.split("+")
        args.test_task_set = args.test_task_set.split("+")
        args.target_task_set = args.target_task_set.split("+")

        train_task_set, target_task_set, test_task_set = args.train_task_set, args.target_task_set, args.test_task_set
        print(len(train_task_set),len(target_task_set),len(test_task_set))

        last_failed = False
        for i, (train, target, test) in enumerate(zip(train_task_set, target_task_set, test_task_set)):
            print("### {i}/{l}: attacking {target} with model trained on {train}".format(train=train,target=target,i=i,
                                                                                     l=len(train_task_set)))
            args.train_task_set, args.target_task_set, args.test_task_set = train, target, test

            try:
                run(args)
                last_failed = False
            except Exception as e:
                if last_failed:
                    print(i,":",e)
                    raise e
                else:
                    last_failed = True
                    print(i,":",e)


    else:
        run(args)


